{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 0: Data preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews.csv')\n",
    "print(df.describe())\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[['Id', 'Text', 'Score']]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for null values in 'Score' column\n",
    "score_null_count = df['Score'].isnull().sum()\n",
    "if score_null_count > 0:\n",
    "    print(f\"Number of null values in 'Score' column: {score_null_count}\")\n",
    "else:\n",
    "    print(\"No null values found in 'Score' column\")\n",
    "\n",
    "# Check for null values in 'Text' column\n",
    "text_null_count = df['Text'].isnull().sum()\n",
    "if text_null_count > 0:\n",
    "    print(f\"Number of null values in 'Text' column: {text_null_count}\")\n",
    "else:\n",
    "    print(\"No null values found in 'Text' column\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for broken data in 'Score' column\n",
    "broken_data = df[(df['Score'] < 1) | (df['Score'] > 5)]\n",
    "if len(broken_data) > 0:\n",
    "    print(\"Broken data found in 'Score' column:\")\n",
    "    print(broken_data)\n",
    "else:\n",
    "    print(\"No broken data found in 'Score' column\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the occurrences of each score\n",
    "score_counts = df['Score'].value_counts()\n",
    "\n",
    "# Create bar plot using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=score_counts.index, y=score_counts.values)\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Scores')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Resample the data to have an equal count for each score\n",
    "def resample_df(df, min_count):\n",
    "    return pd.concat([df[df['Score'] == score].sample(min_count) for score in score_counts.index]) .reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df = resample_df(df, 200)\n",
    "test_df = resample_df(test_df, 50)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot for resampled train data\n",
    "axs[0].bar(df['Score'].value_counts().index, df['Score'].value_counts().values)\n",
    "axs[0].set_xlabel('Score')\n",
    "axs[0].set_ylabel('Count')\n",
    "axs[0].set_title('Train Data')\n",
    "\n",
    "# Plot for resampled test data\n",
    "axs[1].bar(test_df['Score'].value_counts().index, test_df['Score'].value_counts().values)\n",
    "axs[1].set_xlabel('Score')\n",
    "axs[1].set_ylabel('Count')\n",
    "axs[1].set_title('Test Data')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Sentiment analysis\n",
    "\n",
    "### VADER approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example = df['Text'][10]\n",
    "example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sid.polarity_scores(example)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Score'][10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vader_res = df['Text'].apply(lambda text: sid.polarity_scores(text))\n",
    "df['vader_pos'] = vader_res.apply(lambda score: score['pos'])\n",
    "df['vader_neg'] = vader_res.apply(lambda score: score['neg'])\n",
    "df['vader_neu'] = vader_res.apply(lambda score: score['neu'])\n",
    "df['vader_compound'] = vader_res.apply(lambda score: score['compound'])\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=df, x='Score', y='vader_compound')\n",
    "ax.set_title('Compound score by stars')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_sentiment_results(model):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    sns.barplot(data=df, x='Score', y=f'{model}_pos', ax=axs[0])\n",
    "    sns.barplot(data=df, x='Score', y=f'{model}_neu', ax=axs[1])\n",
    "    sns.barplot(data=df, x='Score', y=f'{model}_neg', ax=axs[2])\n",
    "    axs[0].set_title('Positive')\n",
    "    axs[1].set_title('Neutral')\n",
    "    axs[2].set_title('Negative')\n",
    "    plt.show()\n",
    "\n",
    "plot_sentiment_results('vader')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RoBERTa pretrained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "MODEL = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def polarity_scores_roberta(text):\n",
    "    encoded_inputs = tokenizer(text, return_tensors='pt')\n",
    "    logits = model(**encoded_inputs)\n",
    "\n",
    "    scores = logits[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    return {\n",
    "        'roberta_neg': scores[0],\n",
    "        'roberta_neu': scores[1],\n",
    "        'roberta_pos': scores[2]\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "roberta_res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    row_id = row['Id']\n",
    "    row_text = row['Text']\n",
    "    try:\n",
    "        score = polarity_scores_roberta(row_text)\n",
    "        roberta_res[row_id] = score\n",
    "    except RuntimeError:\n",
    "        print(f'Error for id {row_id}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(roberta_res).T\n",
    "results_df = results_df.reset_index().rename(columns={'index': 'Id'})\n",
    "df = df.merge(results_df, how='left')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_sentiment_results('roberta')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
